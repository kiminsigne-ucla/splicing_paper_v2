{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Kimberly/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (101,106,107,108,109,127) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "dpsi_threshold = -0.50\n",
    "\n",
    "exac_spanr = pd.read_table('../../processed_data/exac/exac_SPANR_scores_capped.txt', sep='\\t', header=0)\n",
    "exac_spanr.rename(index=str, inplace=True, columns={'dpsi_spanr_capped' : 'spanr_dpsi',\n",
    "                                                    'dpsi_max_tissue' : 'spanr_dpsi_uncapped'})\n",
    "exac_spanr['spanr_strong_lof'] = np.where(exac_spanr['spanr_dpsi'] <= dpsi_threshold, True, False)\n",
    "\n",
    "\n",
    "exac_exon_vars = pd.read_table('../../processed_data/exac/exac_HAL_scores.txt', sep='\\t', header=0)\n",
    "exac_exon_vars.rename(index=str, inplace=True, columns={'DPSI_pred' : 'hal_dpsi'})\n",
    "exac_exon_vars['hal_strong_lof'] = np.where(exac_exon_vars['hal_dpsi'] <= dpsi_threshold, True, False)\n",
    "\n",
    "\n",
    "exac_intron_cons = pd.read_table('../../processed_data/exac/exac_data_intron_cons.txt', sep='\\t', header=0)\n",
    "\n",
    "exac_ref_rescored = pd.read_table('../../ref/exac/exac_ref_rescored.txt', sep='\\t', header=0)\n",
    "\n",
    "data_annot = pd.read_table('../../processed_data/exac/exac_func_annot.txt', sep='\\t', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_all = pd.merge(data_annot[['id', 'v2_dpsi', 'category', 'strong_lof', 'label', 'mean_cons_score', 'consequence', \n",
    "                                'cadd_score', 'noncoding_score', 'coding_score', 'fitCons_score', 'dann_score', \n",
    "                                'linsight_score']],\n",
    "                   exac_exon_vars[['id', 'hal_dpsi', 'hal_strong_lof']],\n",
    "                   how='left', on='id')\n",
    "\n",
    "data_all = pd.merge(data_all, exac_spanr[['id', 'spanr_dpsi', 'spanr_strong_lof']], \n",
    "                   how='left', on='id')\n",
    "\n",
    "# only keep mutants\n",
    "data_all = data_all[data_all.category == 'mutant']\n",
    "data_exon = data_all[data_all.label == 'exon']\n",
    "data_intron = data_all[data_all.label != 'exon']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def precision_recall(df, var1, var2):\n",
    "    # assume var1 is ground truth\n",
    "    # true positive, both calls agree\n",
    "    num_true_pos = float(len(df[(df[var1] == True) & (df[var2] == True)]))\n",
    "    # false positives, called as positive by var2 but not var1\n",
    "    num_false_pos = float(len(df[(df[var1] == False) & (df[var2] == True)]))\n",
    "    # true negative, both var1 and var2 are negative\n",
    "    num_true_neg = float(len(df[(df[var1] == False) & (df[var2] == False)]))\n",
    "    # false negative, called as negative by var2 but positive by var1\n",
    "    num_false_neg = float(len(df[(df[var1] == True) & (df[var2] == False)]))\n",
    "\n",
    "    # precision, how many selected items are relevant\n",
    "    if num_true_pos + num_false_pos == 0:\n",
    "        precision = float('NaN')\n",
    "    else:\n",
    "        precision = (num_true_pos / (num_true_pos + num_false_pos)) * 100\n",
    "    # recall/sensitivity, how many relevant items are selected\n",
    "    if num_true_pos + num_false_neg == 0:\n",
    "        recall = float('NaN')\n",
    "    else:\n",
    "        recall = (num_true_pos / (num_true_pos + num_false_neg)) * 100\n",
    "    # specificity, ability to correctly detect negatives \n",
    "    specificity = (num_true_neg / (num_true_neg + num_false_pos)) * 100\n",
    "    \n",
    "    return [precision, recall, specificity]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "df = data_all\n",
    "n = 100\n",
    "for i in range(n):\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    specificities = []\n",
    "    df['random_guess'] = [random.choice([True, False]) for j in range(len(df))]\n",
    "    precision, recall, specificity = precision_recall(df, 'strong_lof', 'random_guess')\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "    specificities.append(specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.7050308155367642, 49.238095238095234, 50.457193422313985)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(precisions), np.mean(recalls), np.mean(specificities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pr_score_curve(df, direction, score_width, truth_var, score_var, score_min=None, score_max=None):\n",
    "    # include max as threshold\n",
    "    if score_min is None:\n",
    "        score_min = np.nanmin(df[score_var]).iloc[0] # returns Series\n",
    "    if score_max is None:\n",
    "        score_max = np.nanmax(df[score_var]).iloc[0]\n",
    "    score_thresholds = np.arange(score_min, score_max + score_width, score_width)\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    for threshold in score_thresholds:\n",
    "        # same direction means lower scores are associated with less splicing defects\n",
    "        if direction == 'same':\n",
    "            df['score_var_strong_lof'] = np.where(df[score_var] >= threshold, True, False)\n",
    "        # opposite means higher scores are associated with less splicing defects\n",
    "        elif direction == 'opposite':\n",
    "            df['score_var_strong_lof'] = np.where(df[score_var] <= threshold, True, False)\n",
    "        else:\n",
    "            raise Exception(\"please indicate direction of score assocation, same or opposite\")\n",
    "        df.loc[np.isnan(df[score_var]), 'score_var_strong_lof'] = float('NaN')\n",
    "        precision, recall, specificity = precision_recall(df, truth_var, 'score_var_strong_lof')\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "    result = pd.DataFrame({'threshold' : score_thresholds, 'precision' : precisions, 'recall' : recalls})\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def roc_stats(df, var1, var2):\n",
    "    # assume var1 is ground truth\n",
    "    # true positive, both calls agree\n",
    "    num_true_pos = float(len(df[(df[var1] == True) & (df[var2] == True)]))\n",
    "    # false positives, called as positive by var2 but not var1\n",
    "    num_false_pos = float(len(df[(df[var1] == False) & (df[var2] == True)]))\n",
    "    # true negative, both var1 and var2 are negative\n",
    "    num_true_neg = float(len(df[(df[var1] == False) & (df[var2] == False)]))\n",
    "    # false negative, called as negative by var2 but positive by var1\n",
    "    num_false_neg = float(len(df[(df[var1] == True) & (df[var2] == False)]))\n",
    "\n",
    "    # recall/sensitivity/true positive rate, how many relevant items are selected\n",
    "    if num_true_pos + num_false_neg == 0:\n",
    "        recall = float('NaN')\n",
    "    else:\n",
    "        recall = (num_true_pos / (num_true_pos + num_false_neg))\n",
    "    # specificity, ability to correctly detect negatives \n",
    "    specificity = (num_true_neg / (num_true_neg + num_false_pos))\n",
    "    # false positive rate, 1 - specificity\n",
    "    fp_rate = 1 - specificity\n",
    "    \n",
    "    return [recall, fp_rate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def roc_score_curve(df, direction, score_width, truth_var, score_var, score_min=None, score_max=None):\n",
    "    # include max as threshold\n",
    "    if score_min is None:\n",
    "        score_min = np.nanmin(df[score_var]).iloc[0] # returns Series\n",
    "    if score_max is None:\n",
    "        score_max = np.nanmax(df[score_var]).iloc[0]\n",
    "    score_thresholds = np.arange(score_min, score_max + score_width, score_width)\n",
    "    tp_rates = []\n",
    "    fp_rates = []\n",
    "    for threshold in score_thresholds:\n",
    "        # same direction means lower scores are associated with less splicing defects\n",
    "        if direction == 'same':\n",
    "            df['score_var_strong_lof'] = np.where(df[score_var] >= threshold, True, False)\n",
    "        # opposite means higher scores are associated with less splicing defects\n",
    "        elif direction == 'opposite':\n",
    "            df['score_var_strong_lof'] = np.where(df[score_var] <= threshold, True, False)\n",
    "        else:\n",
    "            raise Exception(\"please indicate direction of score assocation, same or opposite\")\n",
    "        df.loc[np.isnan(df[score_var]), 'score_var_strong_lof'] = float('NaN')\n",
    "        \n",
    "        tp_rate, fp_rate = roc_stats(df, truth_var, 'score_var_strong_lof')\n",
    "        tp_rates.append(tp_rate)\n",
    "        fp_rates.append(fp_rate)\n",
    "    result = pd.DataFrame({'threshold' : score_thresholds, 'true_positive_rate' : tp_rates,\n",
    "                          'false_positive_rate' : fp_rates})\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pr_threshold_curve(df, truth_var, prediction_var):\n",
    "    # for methods that predict dPSI, change threshold where variant is called strong loss of function and compare\n",
    "    # performance\n",
    "    thresholds = np.arange(-1, 0, 0.001)\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    for threshold in thresholds:\n",
    "        df['prediction_var_strong_lof'] = np.where(df[prediction_var] <= threshold, True, False)\n",
    "        df.loc[np.isnan(df[prediction_var]), 'prediction_var_strong_lof'] = float('NaN')\n",
    "        precision, recall, specificity = precision_recall(df, truth_var, 'prediction_var_strong_lof')\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "    result = pd.DataFrame({'threshold' : thresholds, 'precision' : precisions, 'recall' : recalls})\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def roc_threshold_curve(df, truth_var, prediction_var):\n",
    "    # for methods that predict dPSI, change threshold where variant is called strong loss of function and compare\n",
    "    # performance\n",
    "    thresholds = np.arange(-1, 0, 0.001)\n",
    "    tp_rates = []\n",
    "    fp_rates = []\n",
    "    for threshold in thresholds:\n",
    "        df['prediction_var_strong_lof'] = np.where(df[prediction_var] <= threshold, True, False)\n",
    "        df.loc[np.isnan(df[prediction_var]), 'prediction_var_strong_lof'] = float('NaN')\n",
    "        tp_rate, fp_rate = roc_stats(df, truth_var, 'prediction_var_strong_lof')\n",
    "        tp_rates.append(tp_rate)\n",
    "        fp_rates.append(fp_rate)\n",
    "    result = pd.DataFrame({'threshold' : thresholds, 'true_positive_rate' : tp_rates,\n",
    "                          'false_positive_rate' : fp_rates})\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_pr_methods(df, intron=False):\n",
    "    # if intron variants only, don't run HAL (only exonic variants)\n",
    "    fathmm_noncoding_pr_curve = pr_score_curve(df, score_min=0, score_max=1, score_width=0.01, \n",
    "                                           truth_var='strong_lof', score_var='noncoding_score', direction='same')\n",
    "    fathmm_noncoding_pr_curve['method'] = ['fathmm_noncoding'] * len(fathmm_noncoding_pr_curve)\n",
    "\n",
    "    fathmm_coding_pr_curve = pr_score_curve(df, score_min=0, score_max=1, score_width=0.01, \n",
    "                                        truth_var='strong_lof', score_var='coding_score', direction='same')\n",
    "    fathmm_coding_pr_curve['method'] = ['fathmm_coding'] * len(fathmm_coding_pr_curve)\n",
    "    \n",
    "    cadd_pr_curve = pr_score_curve(df, score_width = 0.5, truth_var='strong_lof', score_var='cadd_score', \n",
    "                               direction='same')\n",
    "    cadd_pr_curve['method'] = ['cadd'] * len(cadd_pr_curve)\n",
    "    \n",
    "    fitcons_pr_curve = pr_score_curve(df, score_min=0, score_max=1, score_width = 0.01, \n",
    "                                  truth_var='strong_lof', score_var='fitCons_score', direction='opposite')\n",
    "    fitcons_pr_curve['method'] = ['fitcons'] * len(fitcons_pr_curve)\n",
    "    \n",
    "    dann_pr_curve = pr_score_curve(df, score_min=0, score_max=1, score_width = 0.001, \n",
    "                               truth_var='strong_lof', score_var='dann_score', direction='same')\n",
    "    dann_pr_curve['method'] = ['dann'] * len(dann_pr_curve)\n",
    "    \n",
    "    linsight_pr_curve = pr_score_curve(df, score_min=0, score_max=1, score_width = 0.001, \n",
    "                               truth_var='strong_lof', score_var='linsight_score', direction='opposite')\n",
    "    linsight_pr_curve['method'] = ['linsight'] * len(linsight_pr_curve)\n",
    "    \n",
    "    spanr_pr_curve = pr_threshold_curve(df, 'strong_lof', 'spanr_dpsi')\n",
    "    spanr_pr_curve['method'] = ['spanr'] * len(spanr_pr_curve)\n",
    "    \n",
    "    if not intron:\n",
    "        hal_pr_curve = pr_threshold_curve(df, 'strong_lof', 'hal_dpsi')\n",
    "        hal_pr_curve['method'] = ['hal'] * len(hal_pr_curve)\n",
    "        pr_curve_info = pd.concat([fathmm_noncoding_pr_curve, fathmm_coding_pr_curve, cadd_pr_curve, fitcons_pr_curve,\n",
    "                          dann_pr_curve, linsight_pr_curve, spanr_pr_curve, hal_pr_curve])\n",
    "    else:\n",
    "        pr_curve_info = pd.concat([fathmm_noncoding_pr_curve, fathmm_coding_pr_curve, cadd_pr_curve, fitcons_pr_curve,\n",
    "                              dann_pr_curve, linsight_pr_curve, spanr_pr_curve])\n",
    "    return pr_curve_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_roc_methods(df, intron=False):\n",
    "    # if intron variants only, don't run HAL (only exonic variants)\n",
    "    fathmm_noncoding_roc_curve = roc_score_curve(df, score_min=0, score_max=1, score_width=0.01, \n",
    "                                               truth_var='strong_lof', score_var='noncoding_score', direction='same')\n",
    "    fathmm_noncoding_roc_curve['method'] = ['fathmm_noncoding'] * len(fathmm_noncoding_roc_curve)  \n",
    "    \n",
    "    fathmm_coding_roc_curve = roc_score_curve(df, score_min=0, score_max=1, score_width=0.01, \n",
    "                                            truth_var='strong_lof', score_var='coding_score', direction='same')\n",
    "    fathmm_coding_roc_curve['method'] = ['fathmm_coding'] * len(fathmm_coding_roc_curve)\n",
    "    \n",
    "    cadd_roc_curve = roc_score_curve(df, score_width = 0.5, truth_var='strong_lof', score_var='cadd_score', \n",
    "                                   direction='same')\n",
    "    cadd_roc_curve['method'] = ['cadd'] * len(cadd_roc_curve)\n",
    "    \n",
    "    fitcons_roc_curve = roc_score_curve(df, score_min=0, score_max=1, score_width = 0.01, \n",
    "                                  truth_var='strong_lof', score_var='fitCons_score', direction='opposite')\n",
    "    fitcons_roc_curve['method'] = ['fitcons'] * len(fitcons_roc_curve)\n",
    "    \n",
    "    dann_roc_curve = roc_score_curve(df, score_min=0, score_max=1, score_width = 0.001, \n",
    "                               truth_var='strong_lof', score_var='dann_score', direction='same')\n",
    "    dann_roc_curve['method'] = ['dann'] * len(dann_roc_curve)\n",
    "    \n",
    "    linsight_roc_curve = roc_score_curve(df, score_min=0, score_max=1, score_width = 0.001, \n",
    "                               truth_var='strong_lof', score_var='linsight_score', direction='same')\n",
    "    linsight_roc_curve['method'] = ['linsight'] * len(linsight_roc_curve)\n",
    "    \n",
    "    spanr_roc_curve = roc_threshold_curve(df, 'strong_lof', 'spanr_dpsi')\n",
    "    spanr_roc_curve['method'] = ['spanr'] * len(spanr_roc_curve)\n",
    "    \n",
    "    if not intron:\n",
    "        hal_roc_curve = roc_threshold_curve(df, 'strong_lof', 'hal_dpsi')\n",
    "        hal_roc_curve['method'] = ['hal'] * len(hal_roc_curve)\n",
    "        roc_curve_info = pd.concat([fathmm_noncoding_roc_curve, fathmm_coding_roc_curve, cadd_roc_curve, fitcons_roc_curve,\n",
    "                           dann_roc_curve, linsight_roc_curve, spanr_roc_curve, hal_roc_curve])\n",
    "    else:\n",
    "        roc_curve_info = pd.concat([fathmm_noncoding_roc_curve, fathmm_coding_roc_curve, cadd_roc_curve, fitcons_roc_curve,\n",
    "                           dann_roc_curve, linsight_roc_curve, spanr_roc_curve])\n",
    "    \n",
    "    return roc_curve_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Kimberly/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/Kimberly/anaconda2/lib/python2.7/site-packages/pandas/core/indexing.py:465: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "/Users/Kimberly/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/Kimberly/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "pr_curve_all = run_pr_methods(data_all)\n",
    "pr_curve_all.to_csv('../../processed_data/exac/exac_models_pr_curves_all.txt', sep='\\t', index=False)\n",
    "\n",
    "pr_curve_exon = run_pr_methods(data_exon)\n",
    "pr_curve_exon.to_csv('../../processed_data/exac/exac_models_pr_curves_exon.txt', sep='\\t', index=False)\n",
    "\n",
    "pr_curve_intron = run_pr_methods(data_intron, intron=True)\n",
    "pr_curve_intron.to_csv('../../processed_data/exac/exac_models_pr_curves_intron.txt', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Kimberly/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/Kimberly/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/Kimberly/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "roc_curve_all = run_roc_methods(data_all)\n",
    "roc_curve_all.to_csv('../../processed_data/exac/exac_models_roc_curves_all.txt', sep='\\t', index=False)\n",
    "\n",
    "roc_curve_exon = run_roc_methods(data_exon)\n",
    "roc_curve_exon.to_csv('../../processed_data/exac/exac_models_roc_curves_exon.txt', sep='\\t', index=False)\n",
    "\n",
    "roc_curve_intron = run_roc_methods(data_intron, intron=True)\n",
    "roc_curve_intron.to_csv('../../processed_data/exac/exac_models_roc_curves_intron.txt', sep='\\t', index=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
