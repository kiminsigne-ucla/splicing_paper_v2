{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Kimberly/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (100,105,106,107,108,126) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "dpsi_threshold = -0.50\n",
    "\n",
    "exac_spanr = pd.read_table('../../processed_data/exac/exac_SPANR_scores_capped.txt', sep='\\t', header=0)\n",
    "exac_spanr.rename(index=str, inplace=True, columns={'dpsi_spanr_capped' : 'spanr_dpsi',\n",
    "                                                    'dpsi_max_tissue' : 'spanr_dpsi_uncapped'})\n",
    "exac_spanr['spanr_strong_lof'] = np.where(exac_spanr['spanr_dpsi'] <= dpsi_threshold, True, False)\n",
    "\n",
    "\n",
    "exac_exon_vars = pd.read_table('../../processed_data/exac/exac_HAL_scores.txt', sep='\\t', header=0)\n",
    "exac_exon_vars.rename(index=str, inplace=True, columns={'DPSI_pred' : 'hal_dpsi'})\n",
    "exac_exon_vars['hal_strong_lof'] = np.where(exac_exon_vars['hal_dpsi'] <= dpsi_threshold, True, False)\n",
    "\n",
    "\n",
    "exac_intron_cons = pd.read_table('../../processed_data/exac/exac_data_intron_cons.txt', sep='\\t', header=0)\n",
    "\n",
    "exac_ref_rescored = pd.read_table('../../ref/exac/exac_ref_rescored.txt', sep='\\t', header=0)\n",
    "\n",
    "data_annot = pd.read_table('../../processed_data/exac/exac_func_annot.txt', sep='\\t', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_all = pd.merge(data_annot[['id', 'v2_dpsi', 'category', 'strong_lof', 'mean_cons_score', 'consequence', 'cadd_score',\n",
    "                               'noncoding_score', 'coding_score', 'fitCons_score', 'dann_score', 'linsight_score']],\n",
    "                   exac_exon_vars[['id', 'hal_dpsi', 'hal_strong_lof']],\n",
    "                   how='left', on='id')\n",
    "\n",
    "data_all = pd.merge(data_all, exac_spanr[['id', 'spanr_dpsi', 'spanr_strong_lof']], \n",
    "                   how='left', on='id')\n",
    "\n",
    "# only keep mutants\n",
    "data_all = data_all[data_all.category == 'mutant']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>v2_dpsi</th>\n",
       "      <th>category</th>\n",
       "      <th>strong_lof</th>\n",
       "      <th>mean_cons_score</th>\n",
       "      <th>consequence</th>\n",
       "      <th>cadd_score</th>\n",
       "      <th>noncoding_score</th>\n",
       "      <th>coding_score</th>\n",
       "      <th>fitCons_score</th>\n",
       "      <th>dann_score</th>\n",
       "      <th>linsight_score</th>\n",
       "      <th>hal_dpsi</th>\n",
       "      <th>hal_strong_lof</th>\n",
       "      <th>spanr_dpsi</th>\n",
       "      <th>spanr_strong_lof</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENSE00000332835_007</td>\n",
       "      <td>0.044049</td>\n",
       "      <td>mutant</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000</td>\n",
       "      <td>intron_variant</td>\n",
       "      <td>-0.067665</td>\n",
       "      <td>0.09092</td>\n",
       "      <td>0.00981</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.771372</td>\n",
       "      <td>0.050627</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.003138</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENSE00000338771_002</td>\n",
       "      <td>-0.702978</td>\n",
       "      <td>mutant</td>\n",
       "      <td>True</td>\n",
       "      <td>0.002</td>\n",
       "      <td>intron_variant</td>\n",
       "      <td>0.419634</td>\n",
       "      <td>0.30318</td>\n",
       "      <td>0.00908</td>\n",
       "      <td>0.106106</td>\n",
       "      <td>0.515831</td>\n",
       "      <td>0.793712</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.021768</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENSE00000338771_003</td>\n",
       "      <td>0.228068</td>\n",
       "      <td>mutant</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000</td>\n",
       "      <td>splice_region_variant</td>\n",
       "      <td>1.047715</td>\n",
       "      <td>0.22480</td>\n",
       "      <td>0.03068</td>\n",
       "      <td>0.106106</td>\n",
       "      <td>0.625599</td>\n",
       "      <td>0.814655</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000627</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ENSE00000338771_006</td>\n",
       "      <td>0.173610</td>\n",
       "      <td>mutant</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000</td>\n",
       "      <td>synonymous_variant</td>\n",
       "      <td>1.003092</td>\n",
       "      <td>0.96570</td>\n",
       "      <td>0.91637</td>\n",
       "      <td>0.106106</td>\n",
       "      <td>0.593580</td>\n",
       "      <td>0.330815</td>\n",
       "      <td>0.287071</td>\n",
       "      <td>False</td>\n",
       "      <td>0.020878</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ENSE00000338771_008</td>\n",
       "      <td>0.192334</td>\n",
       "      <td>mutant</td>\n",
       "      <td>False</td>\n",
       "      <td>0.998</td>\n",
       "      <td>missense_variant</td>\n",
       "      <td>4.141625</td>\n",
       "      <td>0.97574</td>\n",
       "      <td>0.96694</td>\n",
       "      <td>0.106106</td>\n",
       "      <td>0.975520</td>\n",
       "      <td>0.474749</td>\n",
       "      <td>0.287071</td>\n",
       "      <td>False</td>\n",
       "      <td>0.017493</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id   v2_dpsi category strong_lof  mean_cons_score  \\\n",
       "1  ENSE00000332835_007  0.044049   mutant      False            0.000   \n",
       "3  ENSE00000338771_002 -0.702978   mutant       True            0.002   \n",
       "4  ENSE00000338771_003  0.228068   mutant      False            0.000   \n",
       "5  ENSE00000338771_006  0.173610   mutant      False            1.000   \n",
       "6  ENSE00000338771_008  0.192334   mutant      False            0.998   \n",
       "\n",
       "             consequence  cadd_score  noncoding_score  coding_score  \\\n",
       "1         intron_variant   -0.067665          0.09092       0.00981   \n",
       "3         intron_variant    0.419634          0.30318       0.00908   \n",
       "4  splice_region_variant    1.047715          0.22480       0.03068   \n",
       "5     synonymous_variant    1.003092          0.96570       0.91637   \n",
       "6       missense_variant    4.141625          0.97574       0.96694   \n",
       "\n",
       "   fitCons_score  dann_score  linsight_score  hal_dpsi hal_strong_lof  \\\n",
       "1       0.000000    0.771372        0.050627       NaN            NaN   \n",
       "3       0.106106    0.515831        0.793712       NaN            NaN   \n",
       "4       0.106106    0.625599        0.814655       NaN            NaN   \n",
       "5       0.106106    0.593580        0.330815  0.287071          False   \n",
       "6       0.106106    0.975520        0.474749  0.287071          False   \n",
       "\n",
       "   spanr_dpsi spanr_strong_lof  \n",
       "1   -0.003138            False  \n",
       "3   -0.021768            False  \n",
       "4   -0.000627            False  \n",
       "5    0.020878            False  \n",
       "6    0.017493            False  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def precision_recall(df, var1, var2):\n",
    "    # assume var1 is ground truth\n",
    "    # true positive, both calls agree\n",
    "    num_true_pos = float(len(df[(df[var1] == True) & (df[var2] == True)]))\n",
    "    # false positives, called as positive by var2 but not var1\n",
    "    num_false_pos = float(len(df[(df[var1] == False) & (df[var2] == True)]))\n",
    "    # true negative, both var1 and var2 are negative\n",
    "    num_true_neg = float(len(df[(df[var1] == False) & (df[var2] == False)]))\n",
    "    # false negative, called as negative by var2 but positive by var1\n",
    "    num_false_neg = float(len(df[(df[var1] == True) & (df[var2] == False)]))\n",
    "\n",
    "    # precision, how many selected items are relevant\n",
    "    if num_true_pos + num_false_pos == 0:\n",
    "        precision = float('NaN')\n",
    "    else:\n",
    "        precision = (num_true_pos / (num_true_pos + num_false_pos)) * 100\n",
    "    # recall/sensitivity, how many relevant items are selected\n",
    "    if num_true_pos + num_false_neg == 0:\n",
    "        recall = float('NaN')\n",
    "    else:\n",
    "        recall = (num_true_pos / (num_true_pos + num_false_neg)) * 100\n",
    "    # specificity, ability to correctly detect negatives \n",
    "    specificity = (num_true_neg / (num_true_neg + num_false_pos)) * 100\n",
    "    \n",
    "    return [precision, recall, specificity]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "df = data_all\n",
    "n = 100\n",
    "for i in range(n):\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    specificities = []\n",
    "    df['random_guess'] = [random.choice([True, False]) for j in range(len(df))]\n",
    "    precision, recall, specificity = precision_recall(df, 'strong_lof', 'random_guess')\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "    specificities.append(specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.9486885480865701, 52.476190476190474, 50.582552909077506)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(precisions), np.mean(recalls), np.mean(specificities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pr_score_curve(df, direction, score_width, truth_var, score_var, score_min=None, score_max=None):\n",
    "    # include max as threshold\n",
    "    if score_min is None:\n",
    "        score_min = np.nanmin(df[score_var]).iloc[0] # returns Series\n",
    "    if score_max is None:\n",
    "        score_max = np.nanmax(df[score_var]).iloc[0]\n",
    "    score_thresholds = np.arange(score_min, score_max + score_width, score_width)\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    for threshold in score_thresholds:\n",
    "        # same direction means lower scores are associated with less splicing defects\n",
    "        if direction == 'same':\n",
    "            df['score_var_strong_lof'] = np.where(df[score_var] >= threshold, True, False)\n",
    "        # opposite means higher scores are associated with less splicing defects\n",
    "        elif direction == 'opposite':\n",
    "            df['score_var_strong_lof'] = np.where(df[score_var] <= threshold, True, False)\n",
    "        else:\n",
    "            raise Exception(\"please indicate direction of score assocation, same or opposite\")\n",
    "        df.loc[np.isnan(df[score_var]), 'score_var_strong_lof'] = float('NaN')\n",
    "        precision, recall, specificity = precision_recall(df, truth_var, 'score_var_strong_lof')\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "    result = pd.DataFrame({'threshold' : score_thresholds, 'precision' : precisions, 'recall' : recalls})\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def roc_stats(df, var1, var2):\n",
    "    # assume var1 is ground truth\n",
    "    # true positive, both calls agree\n",
    "    num_true_pos = float(len(df[(df[var1] == True) & (df[var2] == True)]))\n",
    "    # false positives, called as positive by var2 but not var1\n",
    "    num_false_pos = float(len(df[(df[var1] == False) & (df[var2] == True)]))\n",
    "    # true negative, both var1 and var2 are negative\n",
    "    num_true_neg = float(len(df[(df[var1] == False) & (df[var2] == False)]))\n",
    "    # false negative, called as negative by var2 but positive by var1\n",
    "    num_false_neg = float(len(df[(df[var1] == True) & (df[var2] == False)]))\n",
    "\n",
    "    # recall/sensitivity/true positive rate, how many relevant items are selected\n",
    "    if num_true_pos + num_false_neg == 0:\n",
    "        recall = float('NaN')\n",
    "    else:\n",
    "        recall = (num_true_pos / (num_true_pos + num_false_neg))\n",
    "    # specificity, ability to correctly detect negatives \n",
    "    specificity = (num_true_neg / (num_true_neg + num_false_pos))\n",
    "    # false positive rate, 1 - specificity\n",
    "    fp_rate = 1 - specificity\n",
    "    \n",
    "    return [recall, fp_rate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def roc_score_curve(df, direction, score_width, truth_var, score_var, score_min=None, score_max=None):\n",
    "    # include max as threshold\n",
    "    if score_min is None:\n",
    "        score_min = np.nanmin(df[score_var]).iloc[0] # returns Series\n",
    "    if score_max is None:\n",
    "        score_max = np.nanmax(df[score_var]).iloc[0]\n",
    "    score_thresholds = np.arange(score_min, score_max + score_width, score_width)\n",
    "    tp_rates = []\n",
    "    fp_rates = []\n",
    "    for threshold in score_thresholds:\n",
    "        # same direction means lower scores are associated with less splicing defects\n",
    "        if direction == 'same':\n",
    "            df['score_var_strong_lof'] = np.where(df[score_var] >= threshold, True, False)\n",
    "        # opposite means higher scores are associated with less splicing defects\n",
    "        elif direction == 'opposite':\n",
    "            df['score_var_strong_lof'] = np.where(df[score_var] <= threshold, True, False)\n",
    "        else:\n",
    "            raise Exception(\"please indicate direction of score assocation, same or opposite\")\n",
    "        df.loc[np.isnan(df[score_var]), 'score_var_strong_lof'] = float('NaN')\n",
    "        \n",
    "        tp_rate, fp_rate = roc_stats(df, truth_var, 'score_var_strong_lof')\n",
    "        tp_rates.append(tp_rate)\n",
    "        fp_rates.append(fp_rate)\n",
    "    result = pd.DataFrame({'threshold' : score_thresholds, 'true_positive_rate' : tp_rates,\n",
    "                          'false_positive_rate' : fp_rates})\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fathmm_noncoding_pr_curve = pr_score_curve(data_all, score_min=0, score_max=1, score_width=0.01, \n",
    "                                           truth_var='strong_lof', score_var='noncoding_score', direction='same')\n",
    "fathmm_noncoding_pr_curve['method'] = ['fathmm_noncoding'] * len(fathmm_noncoding_pr_curve)\n",
    "\n",
    "fathmm_noncoding_roc_curve = roc_score_curve(data_all, score_min=0, score_max=1, score_width=0.01, \n",
    "                                           truth_var='strong_lof', score_var='noncoding_score', direction='same')\n",
    "fathmm_noncoding_roc_curve['method'] = ['fathmm_noncoding'] * len(fathmm_noncoding_roc_curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fathmm_coding_pr_curve = pr_score_curve(data_all, score_min=0, score_max=1, score_width=0.01, \n",
    "                                        truth_var='strong_lof', score_var='coding_score', direction='same')\n",
    "fathmm_coding_pr_curve['method'] = ['fathmm_coding'] * len(fathmm_coding_pr_curve)\n",
    "\n",
    "fathmm_coding_roc_curve = roc_score_curve(data_all, score_min=0, score_max=1, score_width=0.01, \n",
    "                                        truth_var='strong_lof', score_var='coding_score', direction='same')\n",
    "fathmm_coding_roc_curve['method'] = ['fathmm_coding'] * len(fathmm_coding_roc_curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cadd_pr_curve = pr_score_curve(data_all, score_width = 0.5, truth_var='strong_lof', score_var='cadd_score', \n",
    "                               direction='same')\n",
    "cadd_pr_curve['method'] = ['cadd'] * len(cadd_pr_curve)\n",
    "\n",
    "cadd_roc_curve = roc_score_curve(data_all, score_width = 0.5, truth_var='strong_lof', score_var='cadd_score', \n",
    "                               direction='same')\n",
    "cadd_roc_curve['method'] = ['cadd'] * len(cadd_roc_curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fitcons_pr_curve = pr_score_curve(data_all, score_min=0, score_max=1, score_width = 0.01, \n",
    "                                  truth_var='strong_lof', score_var='fitCons_score', direction='opposite')\n",
    "fitcons_pr_curve['method'] = ['fitcons'] * len(fitcons_pr_curve)\n",
    "\n",
    "fitcons_roc_curve = roc_score_curve(data_all, score_min=0, score_max=1, score_width = 0.01, \n",
    "                                  truth_var='strong_lof', score_var='fitCons_score', direction='opposite')\n",
    "fitcons_roc_curve['method'] = ['fitcons'] * len(fitcons_roc_curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dann_pr_curve = pr_score_curve(data_all, score_min=0, score_max=1, score_width = 0.01, \n",
    "                               truth_var='strong_lof', score_var='dann_score', direction='same')\n",
    "dann_pr_curve['method'] = ['dann'] * len(dann_pr_curve)\n",
    "\n",
    "dann_roc_curve = roc_score_curve(data_all, score_min=0, score_max=1, score_width = 0.01, \n",
    "                               truth_var='strong_lof', score_var='dann_score', direction='same')\n",
    "dann_roc_curve['method'] = ['dann'] * len(dann_roc_curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "linsight_pr_curve = pr_score_curve(data_all, score_min=0, score_max=1, score_width = 0.01, \n",
    "                               truth_var='strong_lof', score_var='linsight_score', direction='opposite')\n",
    "linsight_pr_curve['method'] = ['linsight'] * len(linsight_pr_curve)\n",
    "\n",
    "linsight_roc_curve = roc_score_curve(data_all, score_min=0, score_max=1, score_width = 0.01, \n",
    "                               truth_var='strong_lof', score_var='linsight_score', direction='opposite')\n",
    "linsight_roc_curve['method'] = ['linsight'] * len(linsight_roc_curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pr_threshold_curve(df, truth_var, prediction_var):\n",
    "    # for methods that predict dPSI, change threshold where variant is called strong loss of function and compare\n",
    "    # performance\n",
    "    thresholds = np.arange(-1, 0, 0.10)\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    for threshold in thresholds:\n",
    "        df['prediction_var_strong_lof'] = np.where(df[prediction_var] <= threshold, True, False)\n",
    "        df.loc[np.isnan(df[prediction_var]), 'prediction_var_strong_lof'] = float('NaN')\n",
    "        precision, recall, specificity = precision_recall(df, truth_var, 'prediction_var_strong_lof')\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "    result = pd.DataFrame({'threshold' : thresholds, 'precision' : precisions, 'recall' : recalls})\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def roc_threshold_curve(df, truth_var, prediction_var):\n",
    "    # for methods that predict dPSI, change threshold where variant is called strong loss of function and compare\n",
    "    # performance\n",
    "    thresholds = np.arange(-1, 0, 0.10)\n",
    "    tp_rates = []\n",
    "    fp_rates = []\n",
    "    for threshold in thresholds:\n",
    "        df['prediction_var_strong_lof'] = np.where(df[prediction_var] <= threshold, True, False)\n",
    "        df.loc[np.isnan(df[prediction_var]), 'prediction_var_strong_lof'] = float('NaN')\n",
    "        tp_rate, fp_rate = roc_stats(df, truth_var, 'prediction_var_strong_lof')\n",
    "        tp_rates.append(tp_rate)\n",
    "        fp_rates.append(fp_rate)\n",
    "    result = pd.DataFrame({'threshold' : thresholds, 'true_positive_rate' : tp_rates,\n",
    "                          'false_positive_rate' : fp_rates})\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hal_pr_curve = pr_threshold_curve(data_all, 'strong_lof', 'hal_dpsi')\n",
    "hal_pr_curve['method'] = ['hal'] * len(hal_pr_curve)\n",
    "\n",
    "hal_roc_curve = roc_threshold_curve(data_all, 'strong_lof', 'hal_dpsi')\n",
    "hal_roc_curve['method'] = ['hal'] * len(hal_roc_curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spanr_pr_curve = pr_threshold_curve(data_all, 'strong_lof', 'spanr_dpsi')\n",
    "spanr_pr_curve['method'] = ['spanr'] * len(spanr_pr_curve)\n",
    "\n",
    "spanr_roc_curve = roc_threshold_curve(data_all, 'strong_lof', 'spanr_dpsi')\n",
    "spanr_roc_curve['method'] = ['spanr'] * len(spanr_roc_curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pr_curve_info = pd.concat([fathmm_noncoding_pr_curve, fathmm_coding_pr_curve, cadd_pr_curve, fitcons_pr_curve,\n",
    "                          dann_pr_curve, linsight_pr_curve, hal_pr_curve, spanr_pr_curve])\n",
    "pr_curve_info.to_csv('../../processed_data/exac/exac_models_pr_curves.txt', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "roc_curve_info = pd.concat([fathmm_noncoding_roc_curve, fathmm_coding_roc_curve, cadd_roc_curve, fitcons_roc_curve,\n",
    "                           dann_roc_curve, linsight_roc_curve, hal_roc_curve, spanr_roc_curve])\n",
    "roc_curve_info.to_csv('../../processed_data/exac/exac_models_roc_curves.txt', sep='\\t', index=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
